================================================================================
ðŸ§  LECTURE 2 - EASY ADHD VERSION ðŸ§ 
================================================================================
APPLIED MACHINE LEARNING - BAYES THEOREM, PROBABILITY & CROSS-VALIDATION
================================================================================

Hey! Welcome back! This lecture is about PROBABILITY and BAYES THEOREM.
Don't panic - I'll explain EVERYTHING with examples! ðŸŽ¯

================================================================================
ðŸŽ¯ PART 1: WHY PROBABILITY? (The Big Picture)
================================================================================

Machine Learning is about making PREDICTIONS under UNCERTAINTY.
We don't KNOW what will happen, but we can calculate how LIKELY it is!

Think of it like weather forecasting:
â€¢ We can't say "It WILL rain tomorrow"
â€¢ But we can say "There's 80% CHANCE of rain tomorrow"

ML does the same:
â€¢ We can't say "This email IS spam"
â€¢ But we can say "There's 95% probability this is spam"

================================================================================
ðŸŽ¯ PART 2: BASIC PROBABILITY REFRESHER
================================================================================

ðŸ“Œ PROBABILITY OF AN EVENT:
--------------------------
P(A) = (Number of ways A can happen) / (Total possible outcomes)

EXAMPLE - Rolling a dice:
What's the probability of getting a 2?
â€¢ Ways to get 2 = 1
â€¢ Total outcomes = 6 (could be 1, 2, 3, 4, 5, or 6)
â€¢ P(getting 2) = 1/6 â‰ˆ 0.167 = 16.7%

EXAMPLE - Two dice, sum = 4:
Total outcomes = 6 Ã— 6 = 36 (each die has 6 options)
Ways to get sum = 4:
â€¢ (1, 3) â†’ 1 + 3 = 4 âœ“
â€¢ (2, 2) â†’ 2 + 2 = 4 âœ“
â€¢ (3, 1) â†’ 3 + 1 = 4 âœ“
Total ways = 3

P(sum = 4) = 3/36 = 1/12 â‰ˆ 0.083 = 8.3%

================================================================================
ðŸŽ¯ PART 3: CONDITIONAL PROBABILITY (Given Something Happened)
================================================================================

This is WHERE THE MAGIC BEGINS! ðŸª„

ðŸ“Œ DEFINITION:
P(A | B) = Probability of A, GIVEN that B already happened

The "|" symbol means "GIVEN THAT"

ðŸ“Œ FORMULA:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚                   P(A âˆ© B)                                               â”‚
â”‚    P(A | B) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚                   P(B)                                                   â”‚
â”‚                                                                          â”‚
â”‚    Read as: "Probability of A given B equals                            â”‚
â”‚              Probability of both A and B happening                      â”‚
â”‚              divided by Probability of B"                               â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ WHY DOES THIS HELP?
----------------------
Conditional probability REDUCES our uncertainty!

EXAMPLE - Two dice:
Question: P(sum = 4 | first die = 1) = ?
Translation: "If the first die is ALREADY 1, what's the probability of sum = 4?"

Original: We needed (1,3), (2,2), or (3,1) out of 36 â†’ P = 3/36

NOW: First die is FIXED at 1!
â€¢ For sum = 4, second die must be 3
â€¢ Second die can be 1, 2, 3, 4, 5, 6 (6 options)
â€¢ Only 1 works (the 3)

P(sum = 4 | D1 = 1) = 1/6

âš¡ KEY INSIGHT: Knowing something REDUCES the sample space!
   Original sample space: 36 possibilities
   After knowing D1 = 1: Only 6 possibilities (whatever D2 can be)

================================================================================
ðŸŽ¯ PART 4: BAYES' THEOREM (The Star of the Show! â­)
================================================================================

This is the MOST IMPORTANT formula in this course!

ðŸ“Œ THE PROBLEM:
--------------
Sometimes we know P(B | A) but want P(A | B)

Real Example:
â€¢ We know: P(Test Positive | Has Disease) = 95%
  (If someone HAS the disease, 95% chance test catches it)
  
â€¢ We want: P(Has Disease | Test Positive) = ???
  (If test is positive, what's the chance they actually have it?)

These are NOT the same! And Bayes helps us flip it!

ðŸ“Œ DERIVATION (Step by Step):
-----------------------------
Step 1: Start with two ways to write P(A âˆ© B)
        
        P(A âˆ© B) = P(A | B) Ã— P(B)    [Definition of conditional prob]
        P(A âˆ© B) = P(B | A) Ã— P(A)    [Same thing, flip A and B]

Step 2: Since both equal P(A âˆ© B), they equal each other:
        
        P(A | B) Ã— P(B) = P(B | A) Ã— P(A)

Step 3: Solve for P(A | B):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚                     P(B | A) Ã— P(A)                                      â”‚
â”‚    P(A | B) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                        P(B)                                              â”‚
â”‚                                                                          â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚    â”‚ BAYES' THEOREM - MEMORIZE THIS! â­                              â”‚  â”‚
â”‚    â”‚                                                                  â”‚  â”‚
â”‚    â”‚              P(B|A) Ã— P(A)                                      â”‚  â”‚
â”‚    â”‚ P(A|B) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚  â”‚
â”‚    â”‚                 P(B)                                            â”‚  â”‚
â”‚    â”‚                                                                  â”‚  â”‚
â”‚    â”‚ What we want = (What we know Ã— Prior) / Evidence                â”‚  â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ THE TERMINOLOGY (Learn These Names!):
---------------------------------------
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚   P(A | B) = POSTERIOR                                                  â”‚
â”‚              "What we want to know" - probability AFTER seeing evidence â”‚
â”‚                                                                          â”‚
â”‚   P(B | A) = LIKELIHOOD                                                 â”‚
â”‚              "How likely is the evidence if hypothesis is true"         â”‚
â”‚                                                                          â”‚
â”‚   P(A) = PRIOR                                                          â”‚
â”‚          "What we believed BEFORE seeing evidence"                      â”‚
â”‚                                                                          â”‚
â”‚   P(B) = EVIDENCE (also called "marginal likelihood")                   â”‚
â”‚          "How common is this evidence overall"                          â”‚
â”‚                                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚                                                                   â”‚  â”‚
â”‚   â”‚              LIKELIHOOD Ã— PRIOR                                  â”‚  â”‚
â”‚   â”‚ POSTERIOR = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚  â”‚
â”‚   â”‚                  EVIDENCE                                        â”‚  â”‚
â”‚   â”‚                                                                   â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ WORKED EXAMPLE - Medical Test:
---------------------------------
Given:
â€¢ P(A) = 0.3 (Prior: 30% of population has condition A)
â€¢ P(B) = 0.4 (40% of tests come back positive overall)
â€¢ P(B | A) = 0.5 (If you HAVE condition, 50% chance test is positive)

Find: P(A | B) = ? (If test is positive, what's prob you have condition?)

Solution using Bayes:
                P(B | A) Ã— P(A)       0.5 Ã— 0.3       0.15
P(A | B) = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€ = 0.375 = 37.5%
                   P(B)                 0.4           0.4

So: Even with a positive test, there's only 37.5% chance you have the condition!

================================================================================
ðŸŽ¯ PART 5: SPECIAL CASES - INDEPENDENCE & MUTUAL EXCLUSIVITY
================================================================================

ðŸ“Œ INDEPENDENT EVENTS:
---------------------
Two events are INDEPENDENT if knowing one tells you NOTHING about the other.

Mathematical definition: P(A âˆ© B) = P(A) Ã— P(B)

What happens to Bayes' Theorem?
If A and B are independent:
â€¢ P(A | B) = P(A)    â† Knowing B doesn't change probability of A!
â€¢ P(B | A) = P(B)    â† Knowing A doesn't change probability of B!

Example: Rolling two dice
â€¢ P(D1 = 3 | D2 = 5) = P(D1 = 3) = 1/6
â€¢ What the second die shows doesn't affect the first die!

ðŸ“Œ MUTUALLY EXCLUSIVE EVENTS:
----------------------------
Two events are MUTUALLY EXCLUSIVE if they CAN'T happen together.

Mathematical definition: P(A âˆ© B) = 0

What happens to Bayes' Theorem?
If A and B are mutually exclusive:
â€¢ P(A | B) = 0    â† If B happened, A definitely didn't!

Example: Rolling ONE die
â€¢ P(getting 3 | got 5) = 0
â€¢ If you rolled a 5, you definitely didn't roll a 3!

ðŸ“Œ SUMMARY TABLE:
----------------
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Scenario          â”‚ Formula                  â”‚ P(A|B) becomes           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ General Case      â”‚ P(B|A)Ã—P(A) / P(B)       â”‚ Calculate normally       â”‚
â”‚ Independent       â”‚ P(Aâˆ©B) = P(A)Ã—P(B)       â”‚ P(A) (B doesn't matter)  â”‚
â”‚ Mutually Exclusiveâ”‚ P(Aâˆ©B) = 0               â”‚ 0 (impossible!)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

================================================================================
ðŸŽ¯ PART 6: LAW OF TOTAL PROBABILITY
================================================================================

ðŸ“Œ THE PROBLEM:
Sometimes we don't know P(B) directly, but we know it for each case!

ðŸ“Œ THE FORMULA:
If Aâ‚, Aâ‚‚, ..., Aâ‚™ cover ALL possibilities (mutually exclusive & exhaustive):

P(B) = P(B|Aâ‚)Ã—P(Aâ‚) + P(B|Aâ‚‚)Ã—P(Aâ‚‚) + ... + P(B|Aâ‚™)Ã—P(Aâ‚™)

Or in math notation: P(B) = Î£áµ¢ P(B|Aáµ¢)Ã—P(Aáµ¢)

ðŸ“Œ EXAMPLE:
A factory has 3 machines making widgets:
â€¢ Machine 1 makes 50% of widgets, 2% are defective
â€¢ Machine 2 makes 30% of widgets, 3% are defective  
â€¢ Machine 3 makes 20% of widgets, 5% are defective

What's the overall defect rate?

P(Defective) = P(D|M1)Ã—P(M1) + P(D|M2)Ã—P(M2) + P(D|M3)Ã—P(M3)
             = (0.02)(0.50) + (0.03)(0.30) + (0.05)(0.20)
             = 0.01 + 0.009 + 0.01
             = 0.029 = 2.9%

================================================================================
ðŸŽ¯ PART 7: MAXIMUM A POSTERIORI (MAP) - Making Decisions!
================================================================================

ðŸ“Œ THE CONCEPT:
In ML, we often have multiple hypotheses (possible classes).
MAP tells us: Pick the hypothesis with HIGHEST POSTERIOR probability!

ðŸ“Œ THE FORMULA:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚   h_MAP = argmax P(h | D)                                               â”‚
â”‚           h âˆˆ H                                                          â”‚
â”‚                                                                          â”‚
â”‚   Using Bayes:                                                          â”‚
â”‚                                                                          â”‚
â”‚                      P(D | h) Ã— P(h)                                    â”‚
â”‚   h_MAP = argmax â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚           h âˆˆ H        P(D)                                             â”‚
â”‚                                                                          â”‚
â”‚   Since P(D) is same for all h, we can IGNORE IT:                       â”‚
â”‚                                                                          â”‚
â”‚   h_MAP = argmax P(D | h) Ã— P(h)                                        â”‚
â”‚           h âˆˆ H                                                          â”‚
â”‚                                                                          â”‚
â”‚   = argmax (LIKELIHOOD Ã— PRIOR)                                         â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ WHAT IS ARGMAX?
------------------
argmax returns the THING that gives the maximum value, not the value itself!

Example:
Scores: Hammad=100, Hadi=67, Maryam=98, Fiza=70

max(scores) = 100 (the highest VALUE)
argmax(scores) = Hammad (the PERSON with highest value)

ðŸ“Œ SPECIAL CASE - MAXIMUM LIKELIHOOD (ML):
-----------------------------------------
If we assume ALL hypotheses are equally likely (uniform prior):
P(hâ‚) = P(hâ‚‚) = P(hâ‚ƒ) = ... (all the same)

Then we can ignore the prior too:

h_ML = argmax P(D | h)
       h âˆˆ H

Just pick the hypothesis that makes the DATA most likely!

================================================================================
ðŸŽ¯ PART 8: THE SHY MATHEMATICIAN EXAMPLE (Classic!)
================================================================================

ðŸ“Œ THE SCENARIO:
You meet a shy student. What's their most likely major?

Data:
â€¢ 100 Math majors, 75% are shy
â€¢ 200 Business majors, 15% are shy
â€¢ 300 CS majors, 50% are shy
â€¢ Total = 600 students

ðŸ“Œ SOLVING WITH BAYES/MAP:

We want: Which major has highest P(Major | Shy)?

Using MAP (ignoring P(Shy) since it's same for all):

P(Math | Shy) âˆ P(Shy | Math) Ã— P(Math)
               = 0.75 Ã— (100/600)
               = 0.75 Ã— 0.167
               = 0.125

P(Business | Shy) âˆ P(Shy | Business) Ã— P(Business)
                   = 0.15 Ã— (200/600)
                   = 0.15 Ã— 0.333
                   = 0.05

P(CS | Shy) âˆ P(Shy | CS) Ã— P(CS)
             = 0.50 Ã— (300/600)
             = 0.50 Ã— 0.500
             = 0.25  â† HIGHEST!

ðŸ“Œ ANSWER: The shy student is most likely a CS major!

Even though Math majors have the highest shyness rate (75%),
there are MANY more CS students, so CS wins!

================================================================================
ðŸŽ¯ PART 9: CROSS-VALIDATION (When You Don't Have Enough Data)
================================================================================

ðŸ“Œ THE PROBLEM:
If you split 70% train, 30% test, you might get "unlucky" with the split.
Maybe all the easy examples end up in training!

ðŸ“Œ K-FOLD CROSS-VALIDATION:
---------------------------
Instead of ONE split, make K splits and train K times!

ALGORITHM:
1. Shuffle your data randomly
2. Split data into K equal parts (called "folds")
3. For i = 1 to K:
   - Use fold i as TEST data
   - Use remaining K-1 folds as TRAINING data
   - Train model, record performance
4. Average all K performances

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  EXAMPLE: 100 samples, K=4                                              â”‚
â”‚                                                                          â”‚
â”‚  Each fold = 25 samples                                                 â”‚
â”‚                                                                          â”‚
â”‚  Iteration 1: [TEST][Train][Train][Train] â†’ Accuracyâ‚                  â”‚
â”‚  Iteration 2: [Train][TEST][Train][Train] â†’ Accuracyâ‚‚                  â”‚
â”‚  Iteration 3: [Train][Train][TEST][Train] â†’ Accuracyâ‚ƒ                  â”‚
â”‚  Iteration 4: [Train][Train][Train][TEST] â†’ Accuracyâ‚„                  â”‚
â”‚                                                                          â”‚
â”‚  Final = (Accuracyâ‚ + Accuracyâ‚‚ + Accuracyâ‚ƒ + Accuracyâ‚„) / 4           â”‚
â”‚                                                                          â”‚
â”‚  EVERY sample gets to be in test set exactly ONCE!                      â”‚
â”‚  EVERY sample gets to be in training set exactly K-1 times!             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ THE FORMULAS:
---------------
Average Performance:
        1   K
MÌ„ = â”€â”€â”€ Ã— Î£ Máµ¢
        K  i=1

Where Máµ¢ = performance on fold i

Variance of Performance (to check stability):
        1   K
Var = â”€â”€â”€ Ã— Î£ (Máµ¢ - MÌ„)Â²
        K  i=1

ðŸ“Œ LEAVE-ONE-OUT CROSS-VALIDATION (LOOCV):
-----------------------------------------
Special case where K = N (number of samples)

Each iteration:
â€¢ 1 sample for testing
â€¢ N-1 samples for training

Good for: VERY small datasets
Bad for: VERY slow (N iterations!)

ðŸ“Œ STRATIFIED SAMPLING:
----------------------
When you have class imbalance (e.g., 95% Class A, 5% Class B):
Regular splitting might put ALL Class B in test set!

STRATIFIED = Keep same ratio in each fold

Example: Dataset is 80% cats, 20% dogs
â€¢ Each fold should also be 80% cats, 20% dogs
â€¢ Use: train_test_split(..., stratify=y)

================================================================================
ðŸŽ¯ PART 10: IID ASSUMPTION (Important for Data!)
================================================================================

IID = Independent and Identically Distributed

ðŸ“Œ INDEPENDENT:
Each data point doesn't affect others.

BAD Example: Collecting health data from your family
â€¢ Your family members share genes, diet, lifestyle
â€¢ Their health conditions are NOT independent!

ðŸ“Œ IDENTICALLY DISTRIBUTED:
All data comes from the SAME source/distribution.

BAD Example: Mixing adult hospital + children hospital data
â€¢ Adults and children have different health patterns
â€¢ Data is from TWO different distributions!

ðŸ“Œ WHY IT MATTERS:
If data is not IID, your model might learn wrong patterns!

================================================================================
ðŸŽ¯ PART 11: TRAIN / VALIDATION / TEST SPLIT
================================================================================

ðŸ“Œ WHY THREE SETS?
-----------------
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRAINING SET (70-80%)                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Purpose: Train the model (learn patterns)                              â”‚
â”‚  The model sees this data and adjusts its parameters                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VALIDATION SET (10-15%)                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Purpose: Tune hyperparameters & select model                          â”‚
â”‚  â€¢ How many layers in neural network?                                   â”‚
â”‚  â€¢ What learning rate?                                                  â”‚
â”‚  â€¢ Which algorithm is best?                                             â”‚
â”‚                                                                          â”‚
â”‚  âš ï¸ NOT used for training, but used for DECISIONS during training      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TEST SET (10-15%)                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  Purpose: FINAL evaluation only!                                        â”‚
â”‚  â€¢ Model never sees this until the very end                            â”‚
â”‚  â€¢ Gives unbiased estimate of real-world performance                   â”‚
â”‚                                                                          â”‚
â”‚  âš ï¸ NEVER use test set to make decisions! Only for final report!       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ DETECTING OVERFITTING:
------------------------
â€¢ Training Accuracy: 98%
â€¢ Validation Accuracy: 60%
â€¢ Gap = 38% â†’ OVERFITTING! Model memorized training data.

================================================================================
ðŸŽ¯ PART 12: LOSS FUNCTIONS RECAP
================================================================================

ðŸ“Œ FOR REGRESSION:
-----------------
MSE (Mean Squared Error):
        1   n
MSE = â”€â”€â”€ Ã— Î£ (Å·áµ¢ - yáµ¢)Â²
        n  i=1

â€¢ Squares errors â†’ big errors punished MORE
â€¢ Good for clean data
â€¢ Smooth, easy to optimize

MAE (Mean Absolute Error):
        1   n
MAE = â”€â”€â”€ Ã— Î£ |Å·áµ¢ - yáµ¢|
        n  i=1

â€¢ Absolute value â†’ all errors treated same
â€¢ Good for noisy data with outliers
â€¢ Harder to optimize (not smooth at 0)

ðŸ“Œ FOR CLASSIFICATION:
---------------------
0/1 Loss:
        1   n
L = â”€â”€â”€ Ã— Î£ ðŸ™(Å·áµ¢ â‰  yáµ¢)
        n  i=1

Where ðŸ™(Å·áµ¢ â‰  yáµ¢) = 1 if wrong, 0 if correct

â€¢ Counts mistakes
â€¢ Not differentiable (can't use gradient descent!)

================================================================================
ðŸŽ¯ PART 13: APPLYING BAYES TO CLASSIFICATION
================================================================================

ðŸ“Œ THE FORMULA FOR CLASSIFICATION:
---------------------------------
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                          â”‚
â”‚  Class_MAP = argmax P(Class | Features)                                 â”‚
â”‚              Class                                                       â”‚
â”‚                                                                          â”‚
â”‚           = argmax P(Features | Class) Ã— P(Class)                       â”‚
â”‚              Class     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚                             P(Features)                                  â”‚
â”‚                                                                          â”‚
â”‚  Since P(Features) is same for all classes:                             â”‚
â”‚                                                                          â”‚
â”‚  Class_MAP = argmax P(Features | Class) Ã— P(Class)                      â”‚
â”‚              Class                                                       â”‚
â”‚                                                                          â”‚
â”‚           = argmax P(xâ‚, xâ‚‚, ..., xâ‚™ | Class) Ã— P(Class)                â”‚
â”‚              Class                                                       â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ðŸ“Œ THE PROBLEM:
Calculating P(xâ‚, xâ‚‚, ..., xâ‚™ | Class) needs TONS of data!
With 10 features, each with 2 values, that's 2Â¹â° = 1024 combinations!

This leads us to... NAIVE BAYES! (Next lecture!)

================================================================================
ðŸŽ¯ CLASSIC WORKED EXAMPLE - Buying Decision
================================================================================

Data (20 records):
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID â”‚ Age(X1) â”‚ Income(X2)â”‚ Decision (C)   â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1  â”‚ Young   â”‚ Low      â”‚ Buys           â”‚
â”‚ 2  â”‚ Young   â”‚ Low      â”‚ Buys           â”‚
â”‚ 3  â”‚ Young   â”‚ Low      â”‚ Buys           â”‚
â”‚ 4  â”‚ Old     â”‚ High     â”‚ Buys           â”‚
â”‚ 5  â”‚ Old     â”‚ High     â”‚ Buys           â”‚
â”‚ 6  â”‚ Young   â”‚ High     â”‚ Buys           â”‚
â”‚ 7  â”‚ Young   â”‚ High     â”‚ Buys           â”‚
â”‚ 8  â”‚ Young   â”‚ High     â”‚ Buys           â”‚
â”‚ 9  â”‚ Young   â”‚ High     â”‚ Buys           â”‚
â”‚ 10 â”‚ Young   â”‚ High     â”‚ Buys           â”‚
â”‚ 11 â”‚ Young   â”‚ Low      â”‚ Doesn't Buy    â”‚
â”‚ 12 â”‚ Young   â”‚ Low      â”‚ Doesn't Buy    â”‚
â”‚ 13 â”‚ Old     â”‚ High     â”‚ Doesn't Buy    â”‚
â”‚ 14 â”‚ Old     â”‚ High     â”‚ Doesn't Buy    â”‚
â”‚ 15 â”‚ Old     â”‚ High     â”‚ Doesn't Buy    â”‚
â”‚ 16 â”‚ Old     â”‚ Low      â”‚ Doesn't Buy    â”‚
â”‚ 17 â”‚ Old     â”‚ Low      â”‚ Doesn't Buy    â”‚
â”‚ 18 â”‚ Old     â”‚ Low      â”‚ Doesn't Buy    â”‚
â”‚ 19 â”‚ Old     â”‚ Low      â”‚ Doesn't Buy    â”‚
â”‚ 20 â”‚ Old     â”‚ Low      â”‚ Doesn't Buy    â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Question: Predict for X1 = Young, X2 = Low

ðŸ“Œ SOLUTION USING BAYES:

STEP 1: Calculate Priors
â€¢ P(Buys) = 10/20 = 0.5
â€¢ P(Doesn't Buy) = 10/20 = 0.5

STEP 2: Calculate Likelihoods (from the data)

For Buys (IDs 1-10):
â€¢ Young: 8 out of 10 â†’ P(Young | Buys) = 0.8
â€¢ Low: 3 out of 10 â†’ P(Low | Buys) = 0.3

For Doesn't Buy (IDs 11-20):
â€¢ Young: 2 out of 10 â†’ P(Young | Doesn't Buy) = 0.2
â€¢ Low: 6 out of 10 â†’ P(Low | Doesn't Buy) = 0.6

STEP 3: Apply Formula

P(Buys | Young, Low) âˆ P(Young|Buys) Ã— P(Low|Buys) Ã— P(Buys)
                      = 0.8 Ã— 0.3 Ã— 0.5
                      = 0.12

P(Doesn't|Young,Low) âˆ P(Young|Doesn't) Ã— P(Low|Doesn't) Ã— P(Doesn't)
                      = 0.2 Ã— 0.6 Ã— 0.5
                      = 0.06

STEP 4: Compare and Decide
0.12 > 0.06

ðŸŽ¯ ANSWER: Buys (because 0.12 is higher!)

================================================================================
ðŸ“š QUICK REFERENCE - ALL FORMULAS
================================================================================

CONDITIONAL PROBABILITY:
P(A|B) = P(A âˆ© B) / P(B)

BAYES' THEOREM:
P(A|B) = P(B|A) Ã— P(A) / P(B)

LAW OF TOTAL PROBABILITY:
P(B) = Î£áµ¢ P(B|Aáµ¢) Ã— P(Aáµ¢)

MAP CLASSIFICATION:
h_MAP = argmax P(D|h) Ã— P(h)

MAXIMUM LIKELIHOOD:
h_ML = argmax P(D|h)

CROSS-VALIDATION AVERAGE:
MÌ„ = (1/K) Ã— Î£áµ¢ Máµ¢

INDEPENDENT EVENTS:
P(A|B) = P(A)

MUTUALLY EXCLUSIVE:
P(A|B) = 0

================================================================================
ðŸŽ¯ EXAM TIPS - WHAT TO REMEMBER!
================================================================================

1. âœ… Bayes flips conditional probability: P(A|B) from P(B|A)
2. âœ… Posterior = (Likelihood Ã— Prior) / Evidence
3. âœ… MAP = argmax (Likelihood Ã— Prior) - ignore evidence!
4. âœ… If independent: P(A|B) = P(A)
5. âœ… If mutually exclusive: P(A|B) = 0
6. âœ… K-Fold: Every point is tested once, trained K-1 times
7. âœ… Stratified: Keeps class proportions in each fold
8. âœ… IID: Data should be Independent and Identically Distributed
9. âœ… Use validation set for tuning, test set ONLY for final eval!

================================================================================
ðŸŽ‰ YOU'RE DOING GREAT! KEEP GOING! ðŸŽ‰
================================================================================
